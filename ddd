'def _unsloth_training_step(\n    self,\n    model: nn.Module,\n    inputs: dict[str, Union[torch.Tensor, Any]],\n    num_items_in_batch: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n    """\n    Perform a training step on a batch of inputs.\n\n    Subclass and override to inject custom behavior.\n\n    Args:\n        model (`nn.Module`):\n            The model to train.\n        inputs (`dict[str, Union[torch.Tensor, Any]]`):\n            The inputs and targets of the model.\n\n            The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n            argument `labels`. Check your model\'s documentation for all accepted arguments.\n\n    Return:\n        `torch.Tensor`: The tensor with training loss on this batch.\n    """\n    model.train()\n    if hasattr(self.optimizer, "train") and callable(self.optimizer.train):\n        self.optimizer.train()\n\n    breakpoint()\n    inputs = self._prepare_inputs(inputs)\n    if is_sagemaker_mp_enabled():\n        loss_mb = smp_forward_backward(model, inputs, self.args.gradient_accumulation_steps)\n        return loss_mb.reduce_mean().detach().to(self.args.device)\n\n    with self.compute_loss_context_manager():\n        loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n\n    del inputs\n    if (\n        self.args.torch_empty_cache_steps is not None\n        and self.state.global_step % self.args.torch_empty_cache_steps == 0\n    ):\n        if is_torch_xpu_available():\n            torch.xpu.empty_cache()\n        elif is_torch_mlu_available():\n            torch.mlu.empty_cache()\n        elif is_torch_musa_available():\n            torch.musa.empty_cache()\n        elif is_torch_npu_available():\n            torch.npu.empty_cache()\n        elif is_torch_mps_available():\n            torch.mps.empty_cache()\n        elif is_torch_hpu_available():\n            logger.warning(\n                "`torch_empty_cache_steps` is set but HPU device/backend does not support empty_cache()."\n            )\n        else:\n            torch.cuda.empty_cache()\n\n    kwargs = {}\n\n    # For LOMO optimizers you need to explicitly use the learnign rate\n    if self.args.optim in [OptimizerNames.LOMO, OptimizerNames.ADALOMO]:\n        kwargs["learning_rate"] = self._get_learning_rate()\n\n    if self.args.n_gpu > 1:\n        loss = loss.mean()  # mean() to average on multi-gpu parallel training\n\n    if self.use_apex:\n        from apex import amp\n\n        with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n            scaled_loss.backward()\n    else:\n        # Finally we need to normalize the loss for reporting if GA loss bug is not fixed during compute loss\n        if (not self.model_accepts_loss_kwargs or num_items_in_batch is None) and self.compute_loss_func is None:\n            loss = loss / self.args.gradient_accumulation_steps\n\n        # Turning off loss scaling w.r.t. gradient accumulation when DeepSpeed is enabled\n        # https://github.com/huggingface/transformers/pull/35808\n        if self.accelerator.distributed_type == DistributedType.DEEPSPEED:\n            kwargs["scale_wrt_gas"] = False\n\n        self.accelerator.backward(loss, **kwargs)\n\n        return loss.detach()\n'
